{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chronos-2 -> MASE Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dep-bootstrap",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "REQUIRED_PIP_PACKAGES = {\n",
    "    \"chronos\": \"chronos-forecasting\",\n",
    "    \"graphviz\": \"graphviz\",\n",
    "}\n",
    "\n",
    "for module_name, package_name in REQUIRED_PIP_PACKAGES.items():\n",
    "    if importlib.util.find_spec(module_name) is None:\n",
    "        print(f\"Installing {package_name}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "    else:\n",
    "        print(f\"{package_name} already installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b9c4cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximilian/dev/University/Yr4/AdvancedDLSystems/Coursework/mase/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/home/maximilian/dev/University/Yr4/AdvancedDLSystems/Coursework/mase/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "SRC_DIR = Path.cwd() / \"src\"\n",
    "if SRC_DIR.exists() and str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "from chop.ir.graph import MaseGraph\n",
    "from chop.passes.graph.analysis.init_metadata import init_metadata_analysis_pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "277146a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('artifacts')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_ID_CHOICES = [\"amazon/chronos-2\"]\n",
    "LOADER_CHOICES = [\"chronos\", \"transformers\"]\n",
    "RUN_MODE_CHOICES = [\"export_only\", \"export_and_draw\", \"draw_only\"]\n",
    "\n",
    "MODEL_ID = \"amazon/chronos-2\"\n",
    "LOADER = \"transformers\"\n",
    "RUN_MODE = \"export_and_draw\"\n",
    "\n",
    "OUTPUT_DIR = Path(\"artifacts\")\n",
    "GRAPH_NAME = \"chronos2_mase_graph\"\n",
    "DEVICE = \"cpu\"\n",
    "TRUST_REMOTE_CODE = False\n",
    "HF_INPUT_NAMES = None  # For chronos models, None auto-resolves to [\"context\"].\n",
    "\n",
    "assert MODEL_ID in MODEL_ID_CHOICES, f\"MODEL_ID must be one of {MODEL_ID_CHOICES}\"\n",
    "assert LOADER in LOADER_CHOICES, f\"LOADER must be one of {LOADER_CHOICES}\"\n",
    "assert RUN_MODE in RUN_MODE_CHOICES, f\"RUN_MODE must be one of {RUN_MODE_CHOICES}\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7267055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_with_chronos(model_id: str, trust_remote_code: bool):\n",
    "    import chronos  \n",
    "\n",
    "    pipeline_cls = getattr(chronos, \"Chronos2Pipeline\", None) or getattr(\n",
    "        chronos, \"ChronosPipeline\", None\n",
    "    )\n",
    "    if pipeline_cls is None:\n",
    "        raise RuntimeError(\"`chronos` package does not expose Chronos2Pipeline/ChronosPipeline.\")\n",
    "\n",
    "    kwargs = {\"trust_remote_code\": True} if trust_remote_code else {}\n",
    "    try:\n",
    "        pipeline = pipeline_cls.from_pretrained(model_id, **kwargs)\n",
    "    except TypeError:\n",
    "        pipeline = pipeline_cls.from_pretrained(model_id)\n",
    "\n",
    "    for attr in (\"model\", \"module\", \"hf_model\"):\n",
    "        value = getattr(pipeline, attr, None)\n",
    "        if isinstance(value, torch.nn.Module):\n",
    "            return value, f\"chronos::{pipeline_cls.__name__}.{attr}\"\n",
    "\n",
    "    if isinstance(pipeline, torch.nn.Module):\n",
    "        return pipeline, f\"chronos::{pipeline_cls.__name__}\"\n",
    "\n",
    "    raise RuntimeError(\"Could not extract a torch.nn.Module from the Chronos pipeline.\")\n",
    "\n",
    "\n",
    "def _load_with_transformers(model_id: str, trust_remote_code: bool):\n",
    "    from transformers import AutoModel, AutoModelForSeq2SeqLM\n",
    "\n",
    "    kwargs = {\"trust_remote_code\": True} if trust_remote_code else {}\n",
    "    errors = []\n",
    "\n",
    "    for loader in (AutoModelForSeq2SeqLM, AutoModel):\n",
    "        try:\n",
    "            model = loader.from_pretrained(model_id, **kwargs)\n",
    "            return model, f\"transformers::{loader.__name__}\"\n",
    "        except Exception as exc:\n",
    "            errors.append(f\"{loader.__name__}: {exc}\")\n",
    "\n",
    "    raise RuntimeError(\" | \".join(errors))\n",
    "\n",
    "\n",
    "def load_chronos_model(loader: str, model_id: str, trust_remote_code: bool):\n",
    "    errors = []\n",
    "\n",
    "    if loader in (\"chronos\"):\n",
    "        try:\n",
    "            return _load_with_chronos(model_id=model_id, trust_remote_code=trust_remote_code)\n",
    "        except Exception as exc:\n",
    "            errors.append(f\"chronos loader failed: {exc}\")\n",
    "            if loader == \"chronos\":\n",
    "                raise\n",
    "\n",
    "    if loader in (\"transformers\"):\n",
    "        try:\n",
    "            return _load_with_transformers(model_id=model_id, trust_remote_code=trust_remote_code)\n",
    "        except Exception as exc:\n",
    "            errors.append(f\"transformers loader failed: {exc}\")\n",
    "            if loader == \"transformers\":\n",
    "                raise\n",
    "\n",
    "    raise RuntimeError(\" ; \".join(errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf708309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at amazon/chronos-2 and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.10.layer.0.SelfAttention.k.weight', 'encoder.block.10.layer.0.SelfAttention.o.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.1.DenseReluDense.wi.weight', 'encoder.block.10.layer.1.DenseReluDense.wo.weight', 'encoder.block.11.layer.0.SelfAttention.k.weight', 'encoder.block.11.layer.0.SelfAttention.o.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.1.DenseReluDense.wi.weight', 'encoder.block.11.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.6.layer.0.SelfAttention.k.weight', 'encoder.block.6.layer.0.SelfAttention.o.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.1.DenseReluDense.wi.weight', 'encoder.block.6.layer.1.DenseReluDense.wo.weight', 'encoder.block.7.layer.0.SelfAttention.k.weight', 'encoder.block.7.layer.0.SelfAttention.o.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.1.DenseReluDense.wi.weight', 'encoder.block.7.layer.1.DenseReluDense.wo.weight', 'encoder.block.8.layer.0.SelfAttention.k.weight', 'encoder.block.8.layer.0.SelfAttention.o.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.1.DenseReluDense.wi.weight', 'encoder.block.8.layer.1.DenseReluDense.wo.weight', 'encoder.block.9.layer.0.SelfAttention.k.weight', 'encoder.block.9.layer.0.SelfAttention.o.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.1.DenseReluDense.wi.weight', 'encoder.block.9.layer.1.DenseReluDense.wo.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to artifacts/chronos2_mase_graph.pt, artifacts/chronos2_mase_graph.mz\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model using transformers::AutoModelForSeq2SeqLM\n",
      "Using hf_input_names=None\n",
      "Constructed MaseGraph with 2131 FX nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to artifacts/chronos2_mase_graph.pt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaving full model format\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseMetadata to artifacts/chronos2_mase_graph.mz\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: artifacts/chronos2_mase_graph.pt and artifacts/chronos2_mase_graph.mz\n",
      "Rendered: artifacts/chronos2_mase_graph.svg\n"
     ]
    }
   ],
   "source": [
    "model, source = load_chronos_model(\n",
    "    loader=LOADER,\n",
    "    model_id=MODEL_ID,\n",
    "    trust_remote_code=TRUST_REMOTE_CODE,\n",
    ")\n",
    "print(f\"Loaded model using {source}\")\n",
    "\n",
    "model.eval()\n",
    "if DEVICE:\n",
    "    if DEVICE.startswith(\"cuda\") and not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA requested but torch.cuda.is_available() is False.\")\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "effective_hf_input_names = HF_INPUT_NAMES\n",
    "if effective_hf_input_names is None and source.startswith(\"chronos::\"):\n",
    "    effective_hf_input_names = [\"context\"]\n",
    "print(f\"Using hf_input_names={effective_hf_input_names}\")\n",
    "\n",
    "mg = MaseGraph(model=model, hf_input_names=effective_hf_input_names)\n",
    "mg, _ = init_metadata_analysis_pass(mg)\n",
    "node_count = sum(1 for _ in mg.nodes)\n",
    "print(f\"Constructed MaseGraph with {node_count} FX nodes\")\n",
    "\n",
    "base_path = OUTPUT_DIR / GRAPH_NAME\n",
    "\n",
    "if RUN_MODE in (\"export_only\", \"export_and_draw\"):\n",
    "    mg.export(str(base_path))\n",
    "    print(f\"Exported: {base_path}.pt and {base_path}.mz\")\n",
    "\n",
    "if RUN_MODE in (\"draw_only\", \"export_and_draw\"):\n",
    "    svg_path = OUTPUT_DIR / f\"{GRAPH_NAME}.svg\"\n",
    "    if shutil.which(\"dot\") is None:\n",
    "        print(\"Skipped SVG draw: Graphviz binary `dot` not found in PATH.\")\n",
    "    else:\n",
    "        try:\n",
    "            mg.draw(str(svg_path))\n",
    "            print(f\"Rendered: {svg_path}\")\n",
    "        except (ImportError, OSError, FileNotFoundError) as exc:\n",
    "            print(f\"Skipped SVG draw: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cea93f3",
   "metadata": {},
   "source": [
    "If we try to run with chronos we will get a not implemented error currently, when using transformers which is how I generated the graph it likely resolved to a supported class, think it did this:\n",
    "\n",
    "- The checkpoint (amazon/chronos-2) contains weights + config.\n",
    "- transformers loaded those weights into a generic Hugging Face model class it knows how to instantiate and trace (maybe a T5 class).\n",
    "- MASE then traced that generic HF model class.\n",
    "\n",
    "**Sooo** therefore we need to now implement support for mase --> not sure how to do that yet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
